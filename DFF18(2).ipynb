{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9407c594-1ae6-445f-8103-315239f89c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197efdf9-ca23-47ac-9d35-a724b1a5d418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/16 10:35:15 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"Data Cleansing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af37322-4563-42aa-8d47-b45433d6930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_student = [\n",
    "    (\"Michael\", \"Science\", 80, \"P\", 90),\n",
    "    (\"Nancy\", \"Mathematics\", 90, \"P\", None),\n",
    "    (\"David\", \"English\", 20, \"F\", 80),\n",
    "    (\"John\", \"Science\", None, \"F\", None),\n",
    "    (\"Blessy\", None, 30, \"F\", 50),\n",
    "    (\"Martin\", \"Mathematics\", None, None, 70),\n",
    "    (None,None,None,None,None)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a39f8e02-52a9-4142-a8da-bf9ba54d1a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data_student))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74269f68-bc9b-4b65-a6cc-8705c6248581",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"Subject\", StringType(), True),\n",
    "    StructField(\"Mark\", IntegerType(), True),\n",
    "    StructField(\"Status\", StringType(), True),\n",
    "    StructField(\"Attendance\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "497038dc-4965-49e9-ae8b-29aec19d4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=data_student, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05eedb1e-819d-44b6-bc83-5f37c61c82d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----+------+----------+\n",
      "|   name|    Subject|Mark|Status|Attendance|\n",
      "+-------+-----------+----+------+----------+\n",
      "|Michael|    Science|  80|     P|        90|\n",
      "|  Nancy|Mathematics|  90|     P|      NULL|\n",
      "|  David|    English|  20|     F|        80|\n",
      "|   John|    Science|NULL|     F|      NULL|\n",
      "| Blessy|       NULL|  30|     F|        50|\n",
      "| Martin|Mathematics|NULL|  NULL|        70|\n",
      "|   NULL|       NULL|NULL|  NULL|      NULL|\n",
      "+-------+-----------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69160781-f30f-4b25-abdd-17f8d60d55a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59248ca6-c589-46bf-8119-cf05074bc7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+----+------+----------+\n",
      "|  name|    Subject|Mark|Status|Attendance|\n",
      "+------+-----------+----+------+----------+\n",
      "|  John|    Science|NULL|     F|      NULL|\n",
      "|Martin|Mathematics|NULL|  NULL|        70|\n",
      "|  NULL|       NULL|NULL|  NULL|      NULL|\n",
      "+------+-----------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.Mark.isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1a6000f-c2f2-445c-bde5-866cd054b551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+----+------+----------+\n",
      "|  name|    Subject|Mark|Status|Attendance|\n",
      "+------+-----------+----+------+----------+\n",
      "|  John|    Science|NULL|     F|      NULL|\n",
      "|Martin|Mathematics|NULL|  NULL|        70|\n",
      "|  NULL|       NULL|NULL|  NULL|      NULL|\n",
      "+------+-----------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"Mark\").isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2b3c403-b9d5-44c1-8fa9-1365442866f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, isnull\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4ae1531-21ec-4d34-904c-eb4984a648c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where ALL columns are null:\n",
      "+----+-------+----+------+----------+\n",
      "|name|Subject|Mark|Status|Attendance|\n",
      "+----+-------+----+------+----------+\n",
      "|NULL|   NULL|NULL|  NULL|      NULL|\n",
      "+----+-------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where ALL columns are null\n",
    "df_all_null = df.filter(\n",
    "    reduce(lambda x, y: x & y, [isnull(col(c)) for c in df.columns])\n",
    ")\n",
    "print(\"Rows where ALL columns are null:\")\n",
    "df_all_null.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57241233-d66a-43c8-896b-8278099a4c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+------+----------+\n",
      "|   name|Subject|Mark|Status|Attendance|\n",
      "+-------+-------+----+------+----------+\n",
      "|Michael|Science|  80|     P|        90|\n",
      "|  David|English|  20|     F|        80|\n",
      "+-------+-------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_na_drop = df.na.drop()\n",
    "df_na_drop.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af37d008-2351-4eed-a1d6-d900575ed983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+------+----------+\n",
      "|   name|Subject|Mark|Status|Attendance|\n",
      "+-------+-------+----+------+----------+\n",
      "|Michael|Science|  80|     P|        90|\n",
      "|  David|English|  20|     F|        80|\n",
      "+-------+-------+----+------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_drop_any = df.na.drop(how='any')\n",
    "df_drop_any.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "607121b1-d039-4d87-93a3-de655691379b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----+------+----------+\n",
      "|   name|    Subject|Mark|Status|Attendance|\n",
      "+-------+-----------+----+------+----------+\n",
      "|Michael|    Science|  80|     P|        90|\n",
      "|  Nancy|Mathematics|  90|     P|      NULL|\n",
      "|  David|    English|  20|     F|        80|\n",
      "|   John|    Science|NULL|     F|      NULL|\n",
      "| Blessy|       NULL|  30|     F|        50|\n",
      "| Martin|Mathematics|NULL|  NULL|        70|\n",
      "+-------+-----------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_drop_all = df.na.drop(how='all')\n",
    "df_drop_all.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d443b41-5e63-4e2a-9a8f-58f3254b99a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----+------+----------+\n",
      "|   name|    Subject|Mark|Status|Attendance|\n",
      "+-------+-----------+----+------+----------+\n",
      "|Michael|    Science|  80|     P|        90|\n",
      "|  Nancy|Mathematics|  90|     P|      NULL|\n",
      "|  David|    English|  20|     F|        80|\n",
      "| Blessy|       NULL|  30|     F|        50|\n",
      "+-------+-----------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo1  = df.na.drop(subset=\"Mark\")\n",
    "demo1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b97051a4-8fe0-4249-8673-5b034ec22c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+------+----------+\n",
      "|   name|Subject|Mark|Status|Attendance|\n",
      "+-------+-------+----+------+----------+\n",
      "|Michael|Science|  80|     P|        90|\n",
      "|  David|English|  20|     F|        80|\n",
      "| Blessy|   NULL|  30|     F|        50|\n",
      "+-------+-------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo2 = df.na.drop(subset=[\"Mark\",\"Attendance\"])\n",
    "demo2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9800e40-0e1e-46ad-b459-8ea93e46cc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----+------+----------+\n",
      "|   name|    Subject|Mark|Status|Attendance|\n",
      "+-------+-----------+----+------+----------+\n",
      "|Michael|    Science|  80|     P|        90|\n",
      "|  Nancy|Mathematics|  90|     P|        -1|\n",
      "|  David|    English|  20|     F|        80|\n",
      "|   John|    Science|  -1|     F|        -1|\n",
      "| Blessy|       NULL|  30|     F|        50|\n",
      "| Martin|Mathematics|  -1|  NULL|        70|\n",
      "|   NULL|       NULL|  -1|  NULL|        -1|\n",
      "+-------+-----------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_na_fill = df.na.fill({'Mark': -1, 'Attendance': -1})\n",
    "df_na_fill.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07aa4c42-200e-4d25-a924-1d8320666821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----+------+----------+\n",
      "|   name|    Subject|Mark|Status|Attendance|\n",
      "+-------+-----------+----+------+----------+\n",
      "|Michael|    Science|  80|     P|        90|\n",
      "|  Nancy|Mathematics|  90|     P|         0|\n",
      "|  David|    English|  20|     F|        80|\n",
      "|   John|    Science|   0|     F|         0|\n",
      "| Blessy|       NULL|  30|     F|        50|\n",
      "| Martin|Mathematics|   0|  NULL|        70|\n",
      "|   NULL|       NULL|   0|  NULL|         0|\n",
      "+-------+-----------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_na_fill = df.na.fill(value=0)\n",
    "df_na_fill.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3718fdc5-962b-4cbe-9553-99863077b204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----+------+----------+\n",
      "|   name|    Subject|Mark|Status|Attendance|\n",
      "+-------+-----------+----+------+----------+\n",
      "|Michael|    Science|  80|     P|        90|\n",
      "|  Nancy|Mathematics|  90|     P|      NULL|\n",
      "|  David|    English|  20|     F|        80|\n",
      "|   John|    Science|NULL|     F|      NULL|\n",
      "| Blessy|         NA|  30|     F|        50|\n",
      "| Martin|Mathematics|NULL|    NA|        70|\n",
      "|     NA|         NA|NULL|    NA|      NULL|\n",
      "+-------+-----------+----+------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_na_fill = df.na.fill(value='NA')\n",
    "df_na_fill.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab8c0c87-f20e-43ab-96d5-7dc933ba7ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"John Doe\", \"New York\", \"USA\", 25, \"john@email.com\"),\n",
    "    (\"Jane Smith\", \"LONDON\", \"UK\", 30, \"JANE@EMAIL.COM\"),\n",
    "    (\"BOB JOHNSON\", \"paris\", \"France\", 35, \"Bob@Email.Com\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e07cbde-b75b-498c-be45-11e86b055e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-------+---+--------------+\n",
      "|       name|    city|country|age|         email|\n",
      "+-----------+--------+-------+---+--------------+\n",
      "|   John Doe|New York|    USA| 25|john@email.com|\n",
      "| Jane Smith|  LONDON|     UK| 30|JANE@EMAIL.COM|\n",
      "|BOB JOHNSON|   paris| France| 35| Bob@Email.Com|\n",
      "+-----------+--------+-------+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data, [\"name\", \"city\", \"country\", \"age\", \"email\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1906d740-3278-4b5e-81d6-5a9f35d45100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import upper, lower, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c64b68ff-bad5-4f69-86e3-40804467b9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All string columns to UPPERCASE:\n",
      "+-----------+--------+-------+---+--------------+\n",
      "|       name|    city|country|age|         email|\n",
      "+-----------+--------+-------+---+--------------+\n",
      "|   JOHN DOE|NEW YORK|    USA| 25|JOHN@EMAIL.COM|\n",
      "| JANE SMITH|  LONDON|     UK| 30|JANE@EMAIL.COM|\n",
      "|BOB JOHNSON|   PARIS| FRANCE| 35| BOB@EMAIL.COM|\n",
      "+-----------+--------+-------+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_upper = df.select([upper(col(c)).alias(c) if dtype == 'string' else col(c) \n",
    "                     for c, dtype in df.dtypes])\n",
    "print(\"All string columns to UPPERCASE:\")\n",
    "df_upper.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0dd86a0-4ce0-406c-8703-0985d4822dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed case conversion:\n",
      "+-----------+--------+-------+---+--------------+\n",
      "|       name|    city|country|age|         email|\n",
      "+-----------+--------+-------+---+--------------+\n",
      "|   JOHN DOE|new york|    USA| 25|john@email.com|\n",
      "| JANE SMITH|  london|     UK| 30|jane@email.com|\n",
      "|BOB JOHNSON|   paris| FRANCE| 35| bob@email.com|\n",
      "+-----------+--------+-------+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_mixed = df.select(\n",
    "    upper(col(\"name\")).alias(\"name\"),\n",
    "    lower(col(\"city\")).alias(\"city\"),\n",
    "    upper(col(\"country\")).alias(\"country\"),\n",
    "    col(\"age\"),\n",
    "    lower(col(\"email\")).alias(\"email\")\n",
    ")\n",
    "print(\"Mixed case conversion:\")\n",
    "df_mixed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bb50042-5b32-48bf-adac-a47caba08ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"JOHN DOE\", \"new york\", \"USA\", \"JOHN@EMAIL.COM\"),\n",
    "    (\"Jane Smith\", \"LONDON\", \"uk\", \"jane@email.com\"),\n",
    "    (\"BOB JOHNSON\", \"paris\", \"france\", \"Bob@Email.Com\"),\n",
    "    (\"ALICE BROWN\", \"BERLIN\", \"GERMANY\", \"ALICE@EMAIL.COM\"),\n",
    "    (\"charlie wilson\", \"london\", \"uk\", \"charlie@email.com\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2038a758-e2ca-4be1-b047-d50c26b96f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+-------+-----------------+\n",
      "|          name|    city|country|            email|\n",
      "+--------------+--------+-------+-----------------+\n",
      "|      JOHN DOE|new york|    USA|   JOHN@EMAIL.COM|\n",
      "|    Jane Smith|  LONDON|     uk|   jane@email.com|\n",
      "|   BOB JOHNSON|   paris| france|    Bob@Email.Com|\n",
      "|   ALICE BROWN|  BERLIN|GERMANY|  ALICE@EMAIL.COM|\n",
      "|charlie wilson|  london|     uk|charlie@email.com|\n",
      "+--------------+--------+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data, [\"name\", \"city\", \"country\", \"email\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f785a4bf-7e00-41eb-83c5-b9b715552a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where city is lowercase:\n",
      "+--------------+--------+-------+-----------------+\n",
      "|          name|    city|country|            email|\n",
      "+--------------+--------+-------+-----------------+\n",
      "|      JOHN DOE|new york|    USA|   JOHN@EMAIL.COM|\n",
      "|   BOB JOHNSON|   paris| france|    Bob@Email.Com|\n",
      "|charlie wilson|  london|     uk|charlie@email.com|\n",
      "+--------------+--------+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_lower_city = df.filter(col(\"city\") == lower(col(\"city\")))\n",
    "print(\"Rows where city is lowercase:\")\n",
    "df_lower_city.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c936f5b-a8f9-470c-a980-b4555c4ed399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where city is lowercase:\n",
      "+-----------+------+-------+---------------+\n",
      "|       name|  city|country|          email|\n",
      "+-----------+------+-------+---------------+\n",
      "| Jane Smith|LONDON|     uk| jane@email.com|\n",
      "|ALICE BROWN|BERLIN|GERMANY|ALICE@EMAIL.COM|\n",
      "+-----------+------+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_lower_city = df.filter(col(\"city\") == upper(col(\"city\")))\n",
    "print(\"Rows where city is lowercase:\")\n",
    "df_lower_city.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "302db1d7-976c-4a8d-a2f5-ebe2498a58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city = df.filter(lower(col(\"city\")) == upper(col(\"city\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bbf1c7-2ed4-4b82-a2b6-b217ce3a3240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
